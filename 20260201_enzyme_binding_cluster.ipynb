{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9fc325aa",
      "metadata": {},
      "source": [
        "# Enzyme binding-site mapping + clustering (Biotite + AtomWorks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "226146c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Environment variable CCD_MIRROR_PATH not set. Will not be able to use function requiring this variable. To set it you may:\n",
            "  (1) add the line 'export VAR_NAME=path/to/variable' to your .bashrc or .zshrc file\n",
            "  (2) set it in your current shell with 'export VAR_NAME=path/to/variable'\n",
            "  (3) write it to a .env file in the root of the atomworks.io repository\n",
            "Environment variable PDB_MIRROR_PATH not set. Will not be able to use function requiring this variable. To set it you may:\n",
            "  (1) add the line 'export VAR_NAME=path/to/variable' to your .bashrc or .zshrc file\n",
            "  (2) set it in your current shell with 'export VAR_NAME=path/to/variable'\n",
            "  (3) write it to a .env file in the root of the atomworks.io repository\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Imports OK\n"
          ]
        }
      ],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import biotite.structure as struc\n",
        "from atomworks.io import parse\n",
        "\n",
        "from scipy.spatial import cKDTree\n",
        "from scipy.cluster.hierarchy import linkage, fcluster\n",
        "from scipy.spatial.distance import squareform\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9e5d6b1",
      "metadata": {},
      "source": [
        "## Download 10 trypsin–inhibitor mmCIF files\n",
        "\n",
        "RCSB download pattern:\n",
        "`https://files.rcsb.org/download/<PDBID>.cif`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8499bf36",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded: 10\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[PosixPath('cifs_trypsin/1bty.cif'),\n",
              " PosixPath('cifs_trypsin/5mng.cif'),\n",
              " PosixPath('cifs_trypsin/2ayw.cif')]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import urllib.request\n",
        "\n",
        "PDB_IDS = [\n",
        "    '1BTY', '5MNG', '2AYW', '1G36', '1K1J',\n",
        "    '3OTJ', '2FTL', '3FP6', '4Y0Y', '6YIV',\n",
        "]\n",
        "\n",
        "OUT_DIR = Path('./cifs_trypsin')\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def download_cif(pdb_id: str, out_dir: Path) -> Path:\n",
        "    pdb_id = pdb_id.lower()\n",
        "    url = f'https://files.rcsb.org/download/{pdb_id}.cif'\n",
        "    out_path = out_dir / f'{pdb_id}.cif'\n",
        "    if out_path.exists() and out_path.stat().st_size > 0:\n",
        "        return out_path\n",
        "    urllib.request.urlretrieve(url, out_path)\n",
        "    return out_path\n",
        "\n",
        "cif_paths = []\n",
        "for pid in PDB_IDS:\n",
        "    p = download_cif(pid, OUT_DIR)\n",
        "    cif_paths.append(p)\n",
        "\n",
        "print('Downloaded:', len(cif_paths))\n",
        "cif_paths[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ae19973",
      "metadata": {},
      "source": [
        "## Parse CIF → AtomArray (AtomWorks)\n",
        "\n",
        "We parse assembly 1 by default. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "5f36e3e1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Atoms: 3234\n",
            "Chain IDs (unique): ['A', 'B', 'C']\n"
          ]
        }
      ],
      "source": [
        "ASSEMBLY_ID = '1'\n",
        "\n",
        "def safe_parse_cif(path: Path, assembly_id: str = '1'):\n",
        "    try:\n",
        "        out = parse(\n",
        "            filename=str(path),\n",
        "            build_assembly=(assembly_id,),\n",
        "            add_missing_atoms=False,\n",
        "            fix_formal_charges=False,\n",
        "            add_id_and_entity_annotations=True,\n",
        "        )\n",
        "        return out['assemblies'][assembly_id][0]\n",
        "    except Exception as e:\n",
        "        print('parse failed:', path.name, repr(e))\n",
        "        return None\n",
        "\n",
        "aa0 = safe_parse_cif(cif_paths[0], ASSEMBLY_ID)\n",
        "print('Atoms:', None if aa0 is None else len(aa0))\n",
        "print('Chain IDs (unique):', None if aa0 is None else sorted(set(map(str, np.unique(aa0.chain_id)))))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b01965c",
      "metadata": {},
      "source": [
        "## Define receptor vs partner\n",
        "\n",
        "For trypsin–BPTI complexes, a common mapping is:\n",
        "- receptor (enzyme) chain: `A`\n",
        "- partner (inhibitor) chain: `B`\n",
        "\n",
        "But chain IDs can differ across entries, so we will print chain IDs per structure and you can adjust.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4ef165ec",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique residue names: ['BEN' 'CA']\n",
            "BEN atoms: 16\n",
            "['C_1' 'C_1' 'C_1' 'C_1' 'C_1' 'C_1' 'C_1' 'C_1' 'C_1' 'C_1' 'C_1' 'C_1'\n",
            " 'C_1' 'C_1' 'C_1' 'C_1']\n",
            "Unique residue names: ['BEN' 'CA']\n",
            "BEN atoms: 14\n",
            "['G_1' 'G_1' 'G_1' 'G_1' 'G_1' 'G_1' 'G_1' 'G_1' 'G_1' 'G_1' 'G_1' 'G_1'\n",
            " 'G_1' 'G_1']\n",
            "Unique residue names: ['1NJ' 'BEN' 'CA']\n",
            "BEN atoms: 9\n",
            "['E_1' 'E_1' 'E_1' 'E_1' 'E_1' 'E_1' 'E_1' 'E_1' 'E_1']\n",
            "Unique residue names: ['CA' 'R11']\n",
            "BEN atoms: 0\n",
            "[]\n",
            "Unique residue names: ['CA' 'FD2']\n",
            "BEN atoms: 0\n",
            "[]\n",
            "parse failed: 3otj.cif TypeError(\"int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error resolving arginine naming ambiguity: operands could not be broadcast together with shapes (10,3) (9,3) . Returning original atom array.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unique residue names: ['CA' 'NA']\n",
            "BEN atoms: 0\n",
            "[]\n",
            "Unique residue names: ['CA']\n",
            "BEN atoms: 0\n",
            "[]\n",
            "Unique residue names: ['CA']\n",
            "BEN atoms: 0\n",
            "[]\n",
            "Unique residue names: ['D86']\n",
            "BEN atoms: 0\n",
            "[]\n",
            "parse failed: 3otj.cif TypeError(\"int() argument must be a string, a bytes-like object or a real number, not 'NoneType'\")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Error resolving arginine naming ambiguity: operands could not be broadcast together with shapes (10,3) (9,3) . Returning original atom array.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CIFs with BEN: 3\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[PosixPath('cifs_trypsin/1bty.cif'),\n",
              " PosixPath('cifs_trypsin/5mng.cif'),\n",
              " PosixPath('cifs_trypsin/2ayw.cif')]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "RECEPTOR_CHAIN = 'A'\n",
        "PARTNER_CHAIN = 'B'\n",
        "\n",
        "\n",
        "for p in cif_paths:\n",
        "    aa = safe_parse_cif(p, ASSEMBLY_ID)\n",
        "    if aa is None:\n",
        "        continue\n",
        "    ch = sorted(set(map(str, np.unique(aa.chain_id))))\n",
        "\n",
        "    # print(aa.get_annotation_categories())\n",
        "    \n",
        "    # print the row that res_name is not water and is_polymer is False\n",
        "    non_poly_het = aa[(~aa.is_polymer) & (aa.res_name != 'HOH')]\n",
        "    print('Unique residue names:', np.unique(non_poly_het.res_name))\n",
        "    \n",
        "    BEN = non_poly_het[non_poly_het.res_name == 'BEN']\n",
        "    print('BEN atoms:', len(BEN))\n",
        "    \n",
        "    print(BEN.chain_iid)\n",
        "\n",
        "# in the end we only look into the cif files that contain BEN\n",
        "cif_paths_with_ben = []\n",
        "for p in cif_paths:\n",
        "    aa = safe_parse_cif(p, ASSEMBLY_ID)\n",
        "    if aa is None:\n",
        "        continue\n",
        "    non_poly_het = aa[(~aa.is_polymer) & (aa.res_name != 'HOH')]\n",
        "    BEN = non_poly_het[non_poly_het.res_name == 'BEN']\n",
        "    if len(BEN) > 0:\n",
        "        cif_paths_with_ben.append(p)\n",
        "        \n",
        "print('CIFs with BEN:', len(cif_paths_with_ben))\n",
        "cif_paths_with_ben[:3]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec0db990",
      "metadata": {},
      "source": [
        "## Geometry: contact masks using Biotite CellList\n",
        "\n",
        "We compute atom-level contact masks, then lift them to residue-level binding-site definitions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "029e2567",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_contacts: 118 min_dist: 1.9067354202270508 clashes: 0\n",
            "receptor atoms in contact: 118 / 3217\n",
            "[False False False ... False False False]\n"
          ]
        }
      ],
      "source": [
        "CONTACT_CUTOFF_A = 5.0\n",
        "CLASH_CUTOFF_A = 1.0\n",
        "\n",
        "def contact_stats_between_atom_sets(coord1, coord2,contact_cutoff= 5.0,clash_cutoff = 1.0,cell_size= 6.0,):\n",
        "    \n",
        "    n1_full = int(len(coord1))\n",
        "    v1 = ~np.isnan(coord1).any(axis=1)\n",
        "    v2 = ~np.isnan(coord2).any(axis=1)\n",
        "    coord1_f = coord1[v1]\n",
        "    coord2_f = coord2[v2]\n",
        "\n",
        "    if len(coord1_f) == 0 or len(coord2_f) == 0:\n",
        "        return 0, float('inf'), 0, np.zeros((n1_full,), dtype=bool)\n",
        "\n",
        "    cl = struc.CellList(coord2_f, cell_size=cell_size)\n",
        "    near_c = cl.get_atoms(coord1_f, contact_cutoff, as_mask=True)  # (n1_f, n2_f)\n",
        "    has_c_f = np.any(near_c, axis=1)\n",
        "    n_contacts = int(has_c_f.sum())\n",
        "\n",
        "    min_dist = float('inf')\n",
        "    if n_contacts > 0:\n",
        "        for i_f, rowmask in enumerate(near_c):\n",
        "            if not np.any(rowmask):\n",
        "                continue\n",
        "            d = np.linalg.norm(coord2_f[rowmask] - coord1_f[i_f], axis=1)\n",
        "            md = float(d.min())\n",
        "            if md < min_dist:\n",
        "                min_dist = md\n",
        "\n",
        "    near_2 = cl.get_atoms(coord1_f, clash_cutoff, as_mask=True)\n",
        "    clash_count = int(np.any(near_2, axis=1).sum())\n",
        "\n",
        "    has_c = np.zeros((n1_full,), dtype=bool)\n",
        "    has_c[v1] = has_c_f\n",
        "    return n_contacts, min_dist, clash_count, has_c\n",
        "\n",
        "def interface_masks(receptor_atoms: struc.AtomArray, partner_atoms: struc.AtomArray):\n",
        "    n_contacts, min_dist, clash_count, rec_mask = contact_stats_between_atom_sets(\n",
        "        receptor_atoms.coord, partner_atoms.coord,\n",
        "        contact_cutoff=CONTACT_CUTOFF_A,\n",
        "        clash_cutoff=CLASH_CUTOFF_A,\n",
        "        cell_size=max(6.0, CONTACT_CUTOFF_A + 1.0),\n",
        "    )\n",
        "    _, _, _, par_mask = contact_stats_between_atom_sets(\n",
        "        partner_atoms.coord, receptor_atoms.coord,\n",
        "        contact_cutoff=CONTACT_CUTOFF_A,\n",
        "        clash_cutoff=CLASH_CUTOFF_A,\n",
        "        cell_size=max(6.0, CONTACT_CUTOFF_A + 1.0),\n",
        "    )\n",
        "    return n_contacts, min_dist, clash_count, rec_mask, par_mask\n",
        "\n",
        "aa = safe_parse_cif(cif_paths_with_ben[0], ASSEMBLY_ID)\n",
        "\n",
        "rec = aa[aa.chain_id == 'A']\n",
        "\n",
        "# this should be ligand BEN\n",
        "par = aa[aa.res_name == 'BEN']\n",
        "\n",
        "nC, dmin, nclash, rec_mask, par_mask = interface_masks(rec, par)\n",
        "print('n_contacts:', nC, 'min_dist:', dmin, 'clashes:', nclash)\n",
        "print('receptor atoms in contact:', int(rec_mask.sum()), '/', len(rec))\n",
        "\n",
        "print(rec_mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8070559b",
      "metadata": {},
      "source": [
        "## Binding-site representation: residue set + representative points\n",
        "\n",
        "We represent a binding site on the receptor by:\n",
        "- `site_set`: frozenset of (chain, res_id, ins, res_name)\n",
        "- `site_points`: CA coords per binding-site residue (or residue centroid)\n",
        "\n",
        "These are the objects we cluster.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4ae48a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "binding-site residues: 20\n",
            "point cloud shape: (20, 3)\n",
            "rg: 6.975156616286565\n",
            "example residues: A:46:HIS;A:177:ASP;A:178:SER;A:179:CYS;A:180:GLN;A:181:GLY;A:182:ASP;A:183:SER;A:197:VAL;A:198:SER;A:199:TRP;A:200:GLY;A:201:SER;A:202:GLY;A:203:CYS;A:204:ALA;A:209:PRO;A:210:GLY;A:211:VAL;A:212:TYR ...\n"
          ]
        }
      ],
      "source": [
        "def _norm_ins(x):\n",
        "    return '' if (x is None or str(x).strip() == '') else str(x)\n",
        "\n",
        "def residue_keys(atom_array):\n",
        "    cats = set(atom_array.get_annotation_categories())\n",
        "    if \"ins_code\" in cats:\n",
        "        ins = [_norm_ins(x) for x in atom_array.ins_code]\n",
        "    else:\n",
        "        ins = [\"\"] * len(atom_array)\n",
        "    # Return a plain Python list of tuples (hashable, predictable)\n",
        "    return list(zip(map(str, atom_array.chain_id), map(int, atom_array.res_id), ins))\n",
        "\n",
        "\n",
        "def binding_site_repr(receptor: struc.AtomArray, receptor_contact_mask: np.ndarray) -> dict:\n",
        "    cats = set(receptor.get_annotation_categories())\n",
        "    has_resn = 'res_name' in cats\n",
        "    has_ins = 'ins_code' in cats\n",
        "\n",
        "    keys = residue_keys(receptor)  # list[tuple]\n",
        "    hit = {keys[i] for i in np.where(receptor_contact_mask)[0]}\n",
        "\n",
        "\n",
        "    if not hit:\n",
        "        return {\n",
        "            'site_set': frozenset(),\n",
        "            'site_points': np.zeros((0, 3), dtype=float),\n",
        "            'site_resi_resn': '',\n",
        "            'site_centroid_x': np.nan,\n",
        "            'site_centroid_y': np.nan,\n",
        "            'site_centroid_z': np.nan,\n",
        "            'site_rg': np.nan,\n",
        "        }\n",
        "\n",
        "    ins_arr = None\n",
        "    if has_ins:\n",
        "        ins_arr = np.array([_norm_ins(x) for x in receptor.ins_code], dtype=object)\n",
        "\n",
        "    def key_sort(k):\n",
        "        ch, rid, ins = k\n",
        "        return (str(ch), int(rid), str(ins))\n",
        "\n",
        "    site_set = []\n",
        "    items = []\n",
        "    points = []\n",
        "\n",
        "    for ch, rid, ins in sorted(hit, key=key_sort):\n",
        "        ins_s = _norm_ins(ins)\n",
        "        m = (receptor.chain_id == ch) & (receptor.res_id == rid)\n",
        "        if has_ins:\n",
        "            m = m & (ins_arr == ins_s)\n",
        "        if not np.any(m):\n",
        "            continue\n",
        "\n",
        "        resn = str(receptor.res_name[m][0]) if has_resn else 'UNK'\n",
        "        resi_str = f\"{ch}:{int(rid)}{ins_s}\"\n",
        "\n",
        "        m_ca = m & (receptor.atom_name == 'CA')\n",
        "        if np.any(m_ca):\n",
        "            p = receptor.coord[m_ca][0]\n",
        "        else:\n",
        "            p = np.nanmean(receptor.coord[m], axis=0)\n",
        "        if np.isnan(p).any():\n",
        "            continue\n",
        "\n",
        "        site_set.append((str(ch), int(rid), ins_s, resn))\n",
        "        items.append(f\"{resi_str}:{resn}\")\n",
        "        points.append(p)\n",
        "\n",
        "    if len(points) == 0:\n",
        "        P = np.zeros((0, 3), dtype=float)\n",
        "        cx = cy = cz = np.nan\n",
        "        rg = np.nan\n",
        "    else:\n",
        "        P = np.vstack(points).astype(float)\n",
        "        C = P.mean(axis=0)\n",
        "        cx, cy, cz = map(float, C.tolist())\n",
        "        rg = float(np.sqrt(np.mean(np.sum((P - C) ** 2, axis=1))))\n",
        "\n",
        "    return {\n",
        "        'site_set': frozenset(site_set),\n",
        "        'site_points': P,\n",
        "        'site_resi_resn': ';'.join(items),\n",
        "        'site_centroid_x': cx,\n",
        "        'site_centroid_y': cy,\n",
        "        'site_centroid_z': cz,\n",
        "        'site_rg': rg,\n",
        "    }\n",
        "\n",
        "site0 = binding_site_repr(rec, rec_mask)\n",
        "print('binding-site residues:', len(site0['site_set']))\n",
        "print('point cloud shape:', site0['site_points'].shape)\n",
        "print('rg:', site0['site_rg'])\n",
        "print('example residues:', site0['site_resi_resn'][:200], '...')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c42c15c1",
      "metadata": {},
      "source": [
        "## 6) Build binding-site dataset across structures\n",
        "\n",
        "We compute the receptor binding site relative to the partner chain for each CIF.\n",
        "If a structure lacks the needed chains, we skip it.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cabd8951",
      "metadata": {},
      "outputs": [],
      "source": [
        "MIN_CONTACTS_KEEP = 1\n",
        "\n",
        "rows = []\n",
        "skipped = []\n",
        "for p in cif_paths:\n",
        "    aa = safe_parse_cif(p, ASSEMBLY_ID)\n",
        "    if aa is None:\n",
        "        skipped.append((p.name, 'parse_failed'))\n",
        "        continue\n",
        "    rec = select_chain_polymer_atoms(aa, RECEPTOR_CHAIN)\n",
        "    par = select_chain_polymer_atoms(aa, PARTNER_CHAIN)\n",
        "    if len(rec) == 0 or len(par) == 0:\n",
        "        skipped.append((p.name, 'missing_chain'))\n",
        "        continue\n",
        "\n",
        "    nC, dmin, nclash, rec_mask, par_mask = interface_masks(rec, par)\n",
        "    if nC < MIN_CONTACTS_KEEP:\n",
        "        skipped.append((p.name, 'too_few_contacts'))\n",
        "        continue\n",
        "\n",
        "    site = binding_site_repr(rec, rec_mask)\n",
        "    rows.append({\n",
        "        'path': str(p.resolve()),\n",
        "        'pdb_id': p.stem.upper(),\n",
        "        'n_contacts_atoms': int(nC),\n",
        "        'min_dist_A': float(dmin),\n",
        "        'clash_count_atoms': int(nclash),\n",
        "        'site_size_res': int(len(site['site_set'])),\n",
        "        'site_set': site['site_set'],\n",
        "        'site_points': site['site_points'],\n",
        "        'site_rg': site['site_rg'],\n",
        "        'site_resi_resn': site['site_resi_resn'],\n",
        "    })\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "print('Kept:', len(df), 'Skipped:', len(skipped))\n",
        "df[['pdb_id','n_contacts_atoms','site_size_res','site_rg']].head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0677335e",
      "metadata": {},
      "source": [
        "## 7) Distance metrics: Jaccard / Chamfer / Hybrid\n",
        "\n",
        "Hybrid distance:\n",
        "d = alpha*(1 - Jaccard) + (1-alpha)*clip(Chamfer/d0, 0, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a5f732d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "def jaccard_distance(a: frozenset, b: frozenset) -> float:\n",
        "    if not a and not b:\n",
        "        return 0.0\n",
        "    inter = len(a & b)\n",
        "    uni = len(a | b)\n",
        "    return 1.0 - (inter / uni if uni > 0 else 0.0)\n",
        "\n",
        "def chamfer_distance(P: np.ndarray, Q: np.ndarray) -> float:\n",
        "    if P.size == 0 and Q.size == 0:\n",
        "        return 0.0\n",
        "    if P.size == 0 or Q.size == 0:\n",
        "        return float('inf')\n",
        "    tQ = cKDTree(Q)\n",
        "    dP, _ = tQ.query(P, k=1)\n",
        "    tP = cKDTree(P)\n",
        "    dQ, _ = tP.query(Q, k=1)\n",
        "    return float(dP.mean() + dQ.mean())\n",
        "\n",
        "def pairwise_distance_matrix(site_sets, site_points, metric='hybrid', alpha=0.8, d0=10.0, chamfer_inf_cap=1e6):\n",
        "    n = len(site_sets)\n",
        "    D = np.zeros((n, n), dtype=float)\n",
        "    for i in range(n):\n",
        "        for j in range(i + 1, n):\n",
        "            dj = jaccard_distance(site_sets[i], site_sets[j])\n",
        "            if metric == 'jaccard':\n",
        "                d = dj\n",
        "            else:\n",
        "                dc = chamfer_distance(site_points[i], site_points[j])\n",
        "                if metric == 'chamfer':\n",
        "                    d = float(dc if np.isfinite(dc) else chamfer_inf_cap)\n",
        "                elif metric == 'hybrid':\n",
        "                    dc_norm = 1.0 if not np.isfinite(dc) else float(np.clip(dc / d0, 0.0, 1.0))\n",
        "                    d = float(alpha * dj + (1.0 - alpha) * dc_norm)\n",
        "                else:\n",
        "                    raise ValueError(f'Unknown metric: {metric}')\n",
        "            D[i, j] = D[j, i] = d\n",
        "    return D\n",
        "\n",
        "print('OK')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "316d54cd",
      "metadata": {},
      "source": [
        "## 8) Cluster binding sites\n",
        "\n",
        "We use average-linkage hierarchical clustering on the distance matrix.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f43b1bfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "CLUSTER_METRIC = 'hybrid'   # jaccard | chamfer | hybrid\n",
        "ALPHA = 0.8\n",
        "D0 = 10.0\n",
        "K = 5  # you can change; use <= len(df)\n",
        "\n",
        "if len(df) < 2:\n",
        "    print('Need at least 2 structures to cluster.')\n",
        "else:\n",
        "    site_sets = df['site_set'].tolist()\n",
        "    site_points = df['site_points'].tolist()\n",
        "    D = pairwise_distance_matrix(site_sets, site_points, metric=CLUSTER_METRIC, alpha=ALPHA, d0=D0)\n",
        "    Z = linkage(squareform(D, checks=False), method='average')\n",
        "    k_used = min(K, len(df))\n",
        "    labels = fcluster(Z, t=k_used, criterion='maxclust').astype(int)\n",
        "    df = df.copy()\n",
        "    df['cluster'] = labels\n",
        "    print('k_used:', k_used)\n",
        "    display(df[['pdb_id','n_contacts_atoms','site_size_res','site_rg','cluster']].sort_values(['cluster','pdb_id']))\n",
        "    print(df['cluster'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8654770",
      "metadata": {},
      "source": [
        "## 9) Heatmap (small N)\n",
        "Useful to eyeball whether clusters make sense.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e77b1b2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "if len(df) >= 2:\n",
        "    site_sets = df['site_set'].tolist()\n",
        "    site_points = df['site_points'].tolist()\n",
        "    D = pairwise_distance_matrix(site_sets, site_points, metric=CLUSTER_METRIC, alpha=ALPHA, d0=D0)\n",
        "    plt.figure(figsize=(6,5))\n",
        "    plt.imshow(D, aspect='auto')\n",
        "    plt.colorbar(label='distance')\n",
        "    plt.title(f'Binding-site distance heatmap (metric={CLUSTER_METRIC})')\n",
        "    plt.xlabel('structure index')\n",
        "    plt.ylabel('structure index')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4361a1b",
      "metadata": {},
      "source": [
        "## 10) Inspect clusters: what residues define them?\n",
        "\n",
        "We print a few representatives and the first site's residue string.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba746a30",
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'cluster' in df.columns:\n",
        "    for cid, sub in df.groupby('cluster'):\n",
        "        print('\\n=== Cluster', cid, 'n=', len(sub), '===')\n",
        "        display(sub[['pdb_id','site_size_res','site_rg','n_contacts_atoms','min_dist_A']].head(5))\n",
        "        print('Example binding-site residues:')\n",
        "        print(sub['site_resi_resn'].iloc[0][:400], '...')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "atomworks",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
